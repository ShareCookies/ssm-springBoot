https://baijiahao.baidu.com/s?id=1660009541007805174&wfr=spider&for=pc
缓存的使用注意事项:（缓存问题）
	缓存和数据库数据一致性问题：
		读写并发的时候，会出现缓存与数据库不一致的场景：
			https://www.cnblogs.com/rjzheng/p/9041659.html
		缓存的三种更新策略：
			1.先更新数据库，再更新缓存
				这套方案，大家是普遍反对的，有如下两点原因：
					原因一（并发时网络不稳，导致缓存不一致）
						同时有请求A和请求B进行更新操作，那么会出现
						（1）线程A更新了数据库
						（2）线程B更新了数据库
						（3）线程B更新了缓存
						（4）线程A更新了缓存
						这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据。
					
					原因二（业务场景角度）！
						（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
						（2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。
			2.先删除缓存，再更新数据库
				延时双删策略：
					先删除缓存，再更新数据库，
					休眠1秒，在删除缓存
						读写并发时，a写（删缓更库）b查（查库更缓），在删就可以避免b的脏缓存。
						
						为什么要延时了：
							因为5前在来个C查询到旧值，然后写入数据库就有可能出现问题，
							当然延时越长问题越能规避，业务需求不是非常严格，是可以忽略的。
				附：
					删写会出现的问题：
						先删缓存，再更新数据库方案。
						当同时有一个请求A进行更新操作，另一个请求B进行查询操作。
						那么会出现如下情形:
						（1）请求A进行写操作，删除缓存
						（2）请求B查询发现缓存不存在
						（3）请求B去数据库查询得到旧值
						（4）请求B将旧值写入缓存
						（5）请求A将新值写入数据库
						上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
					删缓存，更新数据库，更新缓存。该情况应该也不会出问题吧？
			3.先更新数据库，再删除缓存
			
				附：
					更删会出现的问题：
						先更新数据库，再删缓存。
						一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：
						（1）缓存刚好失效
						（2）请求A查询数据库，得一个旧值
						（3）请求B将新值写入数据库
						（4）请求B删除缓存
						（5）请求A将查到的旧值写入缓存
						但这种情况几乎很少出现，因为读的速度比写的快。
			所以3、2策略都行。
	缓存雪崩
		介绍：
			当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。
		如何避免：
			3：不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。
			1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
				？
					现在一般都是数据库线程池访问框架，所以已经有队列了应该，
					所以这里应该是指对某类型key进行访问时，手动写个队列，避免数据库线程池一直卡在某类型上，导致整个系统一直卡死吧。
			2：做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期
				？怎么实现二级缓存
	缓存穿透：
		介绍：
			一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。
			一些恶意的请求会故意查询不存在的key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。

		如何避免：
			3. 过滤非法请求。同一ip大量请求、用户鉴权等。
			2：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。

			1：对一定不存在的key进行过滤。
			可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。
			布隆过滤器...
				https://my.oschina.net/LucasZhu/blog/1813110
				
				布隆过滤器只需要哈希表1/8到1/4的大小就能解决同样的问题，因为hash表是存储了实际数据，而BloomFilter实际上是一个很长的二进制向量和一系列的随机映射函数。
				
				布隆过滤器的工作原理：
					假定存储一亿个WEB页面地址，先建立一个16亿二进制（为什么16亿？），即2亿字节的向量，然后将这16亿个二进制位清零。
					对于每一个WEB页面地址(www.google.com)，用8个随机数产生器（f1,f2,...,f8）（为什么8个？），再用一个随机数产生器G把这8个信息指纹映射到1-16亿中的8个自然数g1,g2,...g8（？），最后把这8个位置的二进制位都置为1。
					对着一亿个WEB页面地址都进行这样的处理后，一个针对WEB页面的布隆过滤器就建成了，见下图。

			
	缓存击穿：
		缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，
		当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。
		如何避免：
			1. 队列
			2. 更新热点数据过期时间。或设置热点数据永不过期
	？
		以上说的加个队列会不靠谱吗，可以写个通用的吧。
		hystrix限流&降级，等方案更靠谱吧
redis的应用案例：
	基于redis的锁实现，为有竞争的业务场景提供锁服务:(使用Redis分布式锁)
		例：
			有一人打开文档编辑时，其它人不提供编辑权限。
		锁实现逻辑：
			key当锁(文档id)，value当锁的拥有者(请求用户id)，过期时间(默认半小时)
		锁获取逻辑：
			有锁则获取失败，无则获取成功。
			过期时间：
				客户端发起延长请求。
				后端接到请求则延长指定key过期时间。
				附：
				浏览器关闭发送请求：
					所以如果强制关闭浏览器则很可能来不及释放锁，文档就会无法编辑一段时间。
					
				浏览器刷新发送请求：
					window.onbeforeunload = () => {console.log("在即将离开当前页面(刷新或关闭)时执行 JavaScript");
					Navigator.sendBeacon();
					//https://developer.mozilla.org/zh-CN/docs/Web/API/Navigator/sendBeacon
					};
		锁释放逻辑：
			判断锁是否是自己的，是则删。
			这个过程有两步骤的操作，要注意避免误删非自己锁。
			解决方案：
				1. 可以用redis Lua脚本来当作一步处理。
			
				2. 或保证判断期间锁一定不会过期...
		例：
			./redis实现锁/RedisLockUtil.java
	Redis做异步队列：
		一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
		缺点：
			在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。
			能不能生产一次消费多次呢？
				使用pub/sub主题订阅者模式，可以实现1:N的消息队列。
