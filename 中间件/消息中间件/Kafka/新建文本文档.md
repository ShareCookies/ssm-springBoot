官网：http://kafka.apache.org/
Kafka教程：
	安装：https://www.cnblogs.com/qingyunzong/p/9005062.html
	介绍：
		https://www.cnblogs.com/qingyunzong/p/9004509.html
		https://www.orchome.com/kafka/index
	架构：https://www.cnblogs.com/qingyunzong/p/9004593.html
	高可用：https://www.cnblogs.com/qingyunzong/p/9004703.html
	Kafka在zookeeper中的存储：https://www.cnblogs.com/qingyunzong/p/9007107.html



## 介绍：

	Kafka是一个分布式消息系统。
	Kafka是一个多分区、多副本且基于 ZooKeeper协调的分布式消息系统。

### 特性：
		目前Kafka已经定位为一个分布式流式处理平台，
		它以高吞吐、
			在一台普通的服务器上既可以达到10W/s的吞吐速率；？
		可持久化、
			快速持久化，可以在O(1)的系统开销下进行消息持久化；？
		可水平扩展、
			完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；
		支持流数据处理等多种特性而被广泛使用。
			？
### 应用：
		1、消息系统：
			Kafka 和传统的消息系统（也称作消息中间件）都具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。与此同时，Kafka 还提供了大多数消息系统难以实现的消息顺序性保障及回溯消费的功能。
		2、存储系统：
			Kafka 把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka 的消息持久化功能和多副本机制，我们可以把Kafka作为长期的数据存储系统来使用，只需要把对应的数据保留策略设置为“永久”或启用主题的日志压缩功能即可。
		3、流式处理平台：
			Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作
	附：
		Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。
			？为什么rabbitMq称为重量级

## Kafka基本概念：

> https://www.cnblogs.com/zjdxr-up/p/16104558.html

### Kafka 体系架构：
	1. 一个典型的 Kafka 体系架构包括 ，若干 Producer、若干 Broker、若干 Consumer，以及一个ZooKeeper集群。
	
	2. Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息
	附：
		其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。。
### Broker 服务代理节点
	对于Kafka而言，Broker可以简单地看作一个独立的Kafka服务实例。
		附大多数情况下也可以将Broker看作一台Kafka服务器，前提是这台服务器上只部署了一个Kafka实例。
		一个或多个Broker组成了一个Kafka集群。
		
	broker作用：
		broker 上存储了消息。
#### Topic：主题
		Kafka中的消息以主题为单位进行归类。
		生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。
		附：
			主题是一个逻辑上的概念。
			用户操作消息的时候，只需指定消息的Topic，即可生产或消费数据，而不必关心数据存于何处。
#### Partition：分区
	主题由为一个或多个分区组成。分区是实际存在的。
	1. 主题的分区可以分布在不同的服务器（broker）上。
	？如何决定分区在那个节点上了。自动分配还是手动配置
	2. 每一条消息被发送到 broker 之前，会根据分区规则选择存储到哪个具体的分区。 
	附：如果分区规则设定得合理，所有的消息都可以均匀地分配到不同的分区中。 
	附：
		1.如果一个主题只对应一个文件，那么这个文件所在的机器I/O将会成为这个主题的性能瓶颈，而分区解决了这个问题。
		2.在创建主题的时候可以通过指定的参数来设置分区的个数，当然也可以在主题创建完成之后去修改分区的数量，通过增加分区的数量可以实现水平扩展。
##### 附：partition 分区构成：
```txt
分区在存储层面可以看作一个可追加的日志文件。
偏移量：
	1.消息在被追加到分区日志文件的时候会分配一个特定的偏移量（offset）。
	2.offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，也就是说，Kafka保证的是分区有序而不是主题有序。
附：
	1.每个partition中的数据又使用多个segment文件存储。？
	2.在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。
	3.如果topic有多个partition，消费数据时就不能保证数据的顺序。
```
##### 附：partition  副本：
	1.Kafka 为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。
		1.同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样）。
	    2.副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。
	    3.副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。
	2.副本的同步机制：
		消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。(这个范围可以通过参数进行配置。)	
		1.AR: 分区中的所有副本统称为AR（Assigned Replicas）。
		2.ISR:
			所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。ISR与HW和LEO有着紧密的关系。
		3.OSR: 
			与 leader 副本同步滞后过多的副本（不包括 leader 副本）组成 OSR (Out-of-Sync Replicas ），由 此可见， AR=ISR+OSR 。在正常情况下，所有 的 follower 副本都应该与 leader 副本保持一定程度 的同步，即 AR=ISR, OSR 集合为空。leader 副本负 责维护和跟踪 ISR 集合中所有 follower 副本 的滞后状态， 当 follower 副本落后太多或失效时，leader 副本会把它从 ISR 集合中剔除 。 如果 OSR 集合中有 follower 副本 “追上’了 leader 副本，那么 leader 副本会把它从 OSR 集合转移至 ISR 集合 。 
		4.HW： HW是High Watermark的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。
			LEO： LEO是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的offset。	
			Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。
			同步复制要求所有能工作的 follower 副本都复制完，这条消息才会被确认为已成功提交，这种复制方式极大地影响了性能。而在异步复制方式下，follower副本异步地从leader副本中复制数据，数据只要被leader副本写入就被认为已经成功提交。
			？
				那kafka生产端如何判断是成功提交了

![分区中各偏移量说明](http://rfy18y9f3.hn-bkt.clouddn.com/GJ4)5})3HSJ2$$)DRUPS0YF.png)

### Producer 生成者

		生产者即数据的发布者。
		该角色将消息发布到Kafka的topic中。
		附：
			生产者发送的消息，随机存储到一个partition中。当然生产者也可以指定数据存储的partition。
### Consumer 消费者
		消费者可以从broker中读取数据。

## 客户端开发

> https://www.cnblogs.com/zjdxr-up/p/16110187.html

### 	1.java实现消息发送：

#### 1.1 客户端开发一个正常的生产逻辑需要具备以下几个步骤：
​	（1）配置生产者客户端参数及创建相应的生产者实例。
​	（2）构建待发送的消息。
​	（3）发送消息。
​	（4）关闭生产者实例。

#### 1.2 java kafka进行消息生产发送代码示例：

```java
public class KafkaProducerAnalysis {
    public static final String brokerList = "localhost:9092";
    public static final String topic = "topic-demo";
    public static Properties initConfig() (
         Properties props = new Properties();
         props.put("bootstrap.servers", brokerList);
    　　  props.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
 　　 　  props.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
　　　　  properties. put ("client. id", "producer. client. id. demo");
         return props;
    }
    public static void main(String[] args) {
        //1.
        Properties props = initConfig();
        //KafkaProducer是线程安全的， 可以在多个线程中共享单个KafkaProducer实例?，也 可以将KafkaProducer实例进行池化来供其他线程调用。
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        //2.
        ProducerRecord<String,String> record = new ProducerRecord<> (topic, "hello, Kafka1 ");
        try {
            //3.
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            //4.
        }
    }
 }
```



#### 1.3 消息对象ProducerRecord :

 	构建的消息对象ProducerRecord, 它并不是单纯意义上的消息，它包含了多个属性 

```java
public class ProducerRecord<K, V> {
        private final String topic; //主题
        private final Integer partition; //分区号
    	//headers字段是消息的头部，它大多用来设定 一些与应用相关的信息，如无需要也可以不用设置。
        private final Headers headers; //消息头部
    	//key是用来指定消息的键， 它不仅是消息的附加信息，还可以用来计算分区号进而可以让消息发往特定的分区。
　　　　 //key可以让消息再进行二次归类， 同一个key的消息会被划分到同 一个分区中
    	//有key的消息还可以支持日志压缩的功能
        private final K key; //键
    	//value是指消息体，一般不为空，如果为空则表示特定的消息-墓碑消息;
        private final V value; //值
    	//timestamp是指消息的时间戳，它有 CreateTime 和 LogAppendTime 两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间.
        private final Long timestamp; //消息的时间戳
　　//省略其他成员方法和构造方法
}
```



### 2. 发送消息的三种模式及实现区别

**1. 发送消息主要有三种模式：** 

​	发后即忘(fire-and-forget)、同步(sync)及异步Casync)。

1. 发后即忘: 它只管往Kafka中发送消息而并不关心消息是否正确到达。在大多数情况下，这种发送方式没有什么问题，不过在某些时候（比如发生不可重试异常时）会造成消息的丢失?。 这种发送方式的性能最高， 可靠性也最差。

2. 同步：

   1. KafkaProducer的 send()方法并非是void类型， 而是Future<RecordMetadata>类型， send()方法有2个重载方法，具体定义如下：

      ```
      public Future<RecordMetadata> send(ProducerRecord<K, V> record)
      public Future<RecordMetadata> send(ProducerRecord<K, V> record,Callback callback)
      ```

   2. 实现同步的发送方式， 可以利用send()返回的 Future 对象实现:


```java
try {
    Future<RecordMetadata> future = producer.send(record);
    //示例中在执行send()方法之后直接链式调用了get()方法来阻塞等待Kaflca的响应，直到消息发送成功， 或者发生异常。 
    RecordMetadata metadata= future.get();
    //返回的RecordMetadata对象里包含了消息的一些元数据信息，比如当前消息的主题、分区号、分区中的偏移量(offset)、 时间戳等。
    System.out.println(metadata.topic() + "-" +metadata.partition() + ":" + metadata.offset());
    } catch (ExecutionException I InterruptedException e) {
    e.printStackTrace () ;
}
```

3. 异步 

   send()方法本身就是异步的

   ```
   public Future<RecordMetadata> send(ProducerRecord<K, V> record,Callback callback)
   ```

### 3. Kafka生产者客户端架构

​                  ![](http://qiniu.58xuejia.cn/Kafka生产者客户端架构.png)

1. 消息在通过send( )方法发往broker 的过程中，有可能需要经过拦截器(Interceptor)、 序列化器(Serializer)和分区器(Parttitioner)的一系列作用之后才能被真正地发往 broker。
2. 拦截器一般不是必需的， 而序列化器是必需的。分区器则看情况是否应用。

#### **拦截器**

　　生产者拦截器既可以用 来在消息发送前做一些准备工作 ，比如按照某个规则过滤不符合要求的消 息、修改消 息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

　　生产者拦截器 的 使用 也 很方便，主要是自定义实现org .apache.kafka. clients. producer.Producerlnterceptor 接口。ProducerInterceptor 接 口中包含 3 个方法 ：

```java
public ProducerRecord<K, V> onSend (ProducerRecord<K, V> record);
public void onAcknowledgement(RecordMetadata metadata, Excepti on exception );
public void close() ;
```

 　KafkaProducer 在将消息序列化和计算分区之前会调用 生产者拦截器 的 onSend（）方法来对消息进行相应 的定制化操作。KafkaProducer 会在消息被应答（ Acknowledgement ）之前或消息发送失败时调用生产者拦截器的onAcknowledgement（）方法，优先于用户设定的Callback 之前执行。 

#### 序列化

　　生产者需要用序列化器(Serializer)把对象转换成字节数组才能通过网络发送给Kafka。 而在对侧， 消费者需要用反序列化器(Deserializer)把从Kafka 中收到的字节数组转换成相应的对象。

　　为 了方便， 消息的key和value都使用了字符串， 对应程序中的序列化器也使用了客户端自带的org.apache.kafka. common. serialization. StringSerializer, 除了用于String 类型的序列化器，还有ByteArray、ByteBuffer、 Bytes、 Double、Integer、 Long这几种类型， 它们都实现了org.apache.kafka. common. serialization. Serializer接口



#### 分区器

分区器的作用 就是为消息 分配分区。

消息 经过 序列化 之后就需要确定它发往的分区：

1. 如果消息ProducerRecord中指定了 partitition字段， 那么就不需要分区器的作用， 因为partition代表的就是所要发往的分区号。

2. 如果消息ProducerRecord中没有 指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。 

Kafka 中提供的默认分区器是org.apache.kafka.clients.producer.intemals.DefaultPartitioner, 它实现了org.apache.kafka.clients.producer.Partitioner 接口， 这个接口中定义了2个方法， 具体如下所示。

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
public void close();
```

其中 partition（）方法用来计算分区号，返回值为 int 类型。partition（）方法中的参数分别表示主题 、键、序列化后的键、值、序列化后的值，以及集群的元数据信息，通过这些信息可以实现功能丰富的分区器。 close（）方法在关闭分区器的时候用来回收一些资源 。

　　默认的分区器会对key 进行哈希（采用MurmurHash2 算法 ，具备高运算性能及低碰撞率），最终根据得到 的 哈希值来计算分区号， 拥有相同 key 的消息会被写入同一个分区 。 如果 key 为 null ，那么消息将会以轮询的方式发往主题内的各个可用分区。



#### 消息累加器

　　整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程 （发送线程）。

​		在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（ RecordAccumulator，也称为消息收集器〉中。Sender 线程负责从RecordAccumulator 中 获取消息并将其发送到 Kafka 中 。

　　**RecordAccumulator 主要用来缓存消息 以便Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能 。**RecordAccumulator 缓存的大 小可以通过生产者客户端参数buffer. memory 配置，默认值为 33554432B ，即32MB 。 如果生产者发送消息的速度超过发送到服务器的速度 ，则会导致生产者空间不足，这个时候 KafkaProducer 的 send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数 max. block . ms 的配置，此参数的默认值为 6 0000,即 60 秒 。

 　Sender 从RecordAccumulator 中 获取缓存的消息之后，会进一 步将原本＜分区，Deque<Producer Batch＞＞的保存形式转变成＜Node , List< ProducerBatch＞的形式，其中 Node 表示 Kafka集群的 broker 节点 。对于网络连接来说，生产者客户端是与具体 的 broker 节点建立的连接，也就消息累加器

　　整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程 （发送线程）。在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（ RecordAccumulator，也称为消息收集器〉中。Sender 线程负责从RecordAccumulator 中 获取消息并将其发送到 Kafka 中 。

　　**RecordAccumulator 主要用来缓存消息 以便Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能 。**RecordAccumulator 缓存的大 小可以通过生产者客户端参数buffer. memory 配置，默认值为 33554432B ，即32MB 。 如果生产者发送消息的速度超过发送到服务器的速度 ，则会导致生产者空间不足，这个时候 KafkaProducer 的 send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数 max. block . ms 的配置，此参数的默认值为 6 0000,即 60 秒 。

 　Sender 从RecordAccumulator 中 获取缓存的消息之后，会进一 步将原本＜分区，Deque<Producer Batch＞＞的保存形式转变成＜Node , List< ProducerBatch＞的形式，其中 Node 表示 Kafka集群的 broker 节点 。对于网络连接来说，生产者客户端是与具体 的 broker 节点建立的连接，也就是 向具体的broker 节点发送消息，而并不关心消息属于哪一个分区；而对于KafkaProducer的应用逻辑而言 ，我们只 关注向哪个分区中发送哪些消息，所 以在这里需要做一个应用逻辑层面到网络 1/0 层面的转换。

　　元数据是指 Kafka 集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的 leader 副本分配在哪个节点上，follower 副本分配在哪些节点上，哪些副本在 AR 、ISR 等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。发送哪些消息，所 以在这里需要做一个应用逻辑层面到网络 1/0 层面的转换。

### 重要的生产者参数

　　**1.acks**

​				 这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。acks 是生产者客户端中一个非常重要的参数，它涉及消息的可靠性和吞吐量之间的权衡。　　acks 参数有 3 种类型的值（都是字符串类型）。

　　　　acks =1 : 默认值即为l 。生产者发送消息之后，只要分区的leader 副本成功写入消息，那么它就会收到来自服务端的成功响应 。 如果消息无法写入 leader 副本，比如在leader 副本崩溃、重新选举新的leader 副本的过程中，那么生产者就会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息 。如果消息写入 leader 副本并返回成功响应给生产者，且在被其他 follower 副本拉取之前 leader 副本崩溃，那么此时消息还是会丢失，因为新选举的 leader 副本中并没有这条对应的消息 。 acks 设置为l ，是消息可靠性和吞吐量之间的折中方案。

　　　　 acks = 0 :生产者发送消 息之后不需要等待任何服务端的响应。如果在消息从发送到写入 Kafka 的过程中出现某些异常，导致 Kafka 并没有收到这条消息，那么生产者也无从得知，消息也就丢失了。在其他配置环境相同的情况下，acks 设置为 0 可以达到最大的吞吐量。

　　　　 acks ＝- l 或 acks =all : 生产者在消 息发送之后，需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。在其他配置环境相同的情况下，acks 设置为-1(all ）可以达到最强的可靠性。但这并不意味着消息就一定可靠，因为 ISR 中可能只有 leader 副本，这样就退化成了 acks= l 的情况。

　　**2.max.request.size**

　　　　 这个参数用来限制生产者客户端能发送的消息的最大值，默认值为1048576B ，即lMB 。一般情况下，这个默认值就可以满足大多数的应用场景了。

　　**3.retries 和 retry. backoff.ms**

　　　　 retries 参数用来配置生产者重试的次数，默认值为 0，即在发生异常的时候不进行任何重试动作。消息在从生产者发出到成功写入服务器之前可能发生一些临时性的异常，比如网络抖动、leader 副本的选举等，这种异常往往是可以自行恢复的，生产者可以通过配置 retries大于 0 的值，以此通过 内 部重试来恢复而不是一昧地将异常抛给生产者的应用程序。 如果重试达到设定的次数 ，那么生产者就会放弃重试并返回异常。

　　　　不过并不是所有的异常都是可以通过重试来解决的，比如消息太大，超过 max.request.size 参数配置的值时，这种方式就不可行了。 重试还和另一个参数 retry.backoff.ms 有关，这个参数的默认值为100 ，它用来设定两次重试之间的时间间隔，避免无效的频繁重试。在配置 retries 和retry.backoff.ms之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试 。

　　**4.compression.type**

　　 　这个参数用来指定消息的压缩方式，默认值为“ none ”，即默认情况下，消息不会被压缩。该参数还可以配置为“ gzip ”,“ snappy ” 和“ lz4 ”。 对消息进行压缩可以极大地减少网络传输量 、降低网络 IO ，从而提高整体的性能 。**消息压缩是一种使用时间换空间的优化方式**，如果对时延有一定的要求?，则不推荐对消息进行压缩 。

　　**5. request.timeout.ms**

　　　　 这个参数用来配置 Producer 等待请求响应的最长时间，默认值为 3 0000( ms ）。请求超时之后可以选择进行重试。注意这个参数需要 比 broker 端参数 replica.lag.time.max.ms 的值要大 ，这样可以减少因客户端重试而引起的消息重复的概率。



## 消费者开发

> https://www.cnblogs.com/zjdxr-up/p/16114877.html



### 消费者与消费组

  1. 消费者(Consumer)负责订阅Kafka 中的主题(Topic), 并且从订阅的主题上拉取消息。与其他一些消息中间件不同的是： 在Kafka 的消费理念中还有一层消费组(Consumer Group)的概念， 每一个消费者只隶属于一个消费组。

     ​	•  当消息发布到主题后， 只会被投递给订阅它的每个消费组中的一个消费者。 

     ​	•  且每一个分区只能被一个消费组中的一个消费者所消费。

     ​	•  每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。

　2. 对于消息中间件而言，一般有两种消息投递模式：点对点(P2P, Point-to-Point)模式和发布／订阅(Pub/ Sub)模式。

​		•  点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。

​		•  发布订阅模式定义了如何向 一个内容节点发布和订阅消息，这个内容节点称为主题(Topic) , 主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布／订阅模式在消息的一对多广播时采用。Kafka 同时支待两种消息投递模式，而这正是得益于消费者与消费组模型的契合：

　　　　 • 如果所有的消费者都隶属于同一个消费组，那么所有的消息就会以均衡地的机会投递给所有消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。

　　 　	• 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布／订阅模式的应用。

　总结：消费组是一个逻辑上的概念，它将旗下的消费者进行归类，来实现消息的点对点、发布等功能。

### 消息消费过程及代码

　　1. 一个正常的消费逻辑需要具备以下几个步骤：

　　　　(1) 配置消费者客户端参数及创建相应的消费者实例。

　　　　(2) 订阅主题。

　　　　(3)拉取消息并消费。

　　　　(4) 提交消费位移。

　　　　(5)关闭消费者实例。

​	2.例
```java
public class KafkaConsumerAnalysis {
    public static final String brokerList = "localhost:9092";
    public static final String topic = "topic-demo";
    public static final String groupid = "group.demo";
    public static final AtomicBoolean isRunning = new AtomicBoolean(true);
    public static Properties initConfig () {
        Properties props= new Properties();
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS—CONFIG,StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(ConsumerConfig.GROUP—ID_CONFIG, groupid);
        props. put (ConsumerConfig. CLIENT_ID _ CONFIG, "client. id. demo");
        return props;
    }

    public static void main(String[] args) (
        //1.
        Properties props= initConfig();
        KafkaConsumer<String, String> consumer= new KafkaConsumer<>(props);
        //2.
        //通过 subscribe()方法订阅主题具有 消费者自动再均衡的功能，
        //在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。？
        consumer.subscribe(Arrays.asList(topic));
        try {
            //?
            while (isRunning. get()) {
                //3.
                ConsumerRecords<String, String> records=
                    consumer.poll(Duration.ofMillis(lOOO));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println("topic="+record.topic()+ ", partition = "+         record.partition()+ ", offset="+ record.offset());
                    System.out.println("key ="+record.key()+ ", value="+ record.value());
                //do something to process record.
                    //4.?
                }
            }
        } catch(Exception e) {
            log.error("occur exception", e);
        } finally {
            //5.
            consumer.close();
        }
    }
}
```



3.附：

如果我们事先并不知道主题中有多少个分区怎么办,KafkaConsumer中的partitionsFor ()方法可以用来查询指定主题的元数据信息，partitionsFor()方法的具体定义如下： 

```java
public List<Partitioninfo> partitionsFor(String topic)
```

其中 Partitionlnfo类型即为主题的分区元数据信息，此类的主要结构如下：

```
public class Partitioninfo {
	//主题名称
    private final String topic;
    private final int partition;
    //leader代表分区的leader副本所在的位置
    private final Node leader;
    //replicas代表分区的AR集合，inSyncReplicas代表分区的ISR集合，offlineReplicas代表分区的OSR集合。
    private final Node[] replicas;
    private final Node[] inSyncReplicas;
    private final Node[] offlineReplicas;
    ／／这里省略了构造函数、属性提取、toString等方法
}
```

4.？

所以分区与消费组、消费者之间的关系又是什么了，一个分区对应一个消费者，一个分区对应多个消费者

### 消息消费模式

​		Kafka中的消费是基于 拉模式的。消息的消费一般有两种模式：推模式和 拉模式。推模式是服务端主动将消息推送给消费者， 而 拉模式是消费者主动向服务端发起请求来拉取消息。

​		Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll()方法，而poll()方法返回的是所订阅的主题（分区）上的一组消息。 对于poll()方法而言，如果某些分区中没有可供消费的消息，那么此分区对应 的消息拉取的结果就为空；如果订阅的所有分区中都没有可供消费的消息， 那么poll()方法返回为空的消息集合

　　消费者消费到 的每条消息的类型为ConsumerRecord(注意与ConsumerRecords 的区别，ConsumerRecords为一次获取到的消息集），这个和生产者发送的消息类型ProducerRecord相对应，不过ConsumerRecord中的内容更加丰富，具体的结构参考如下代码：

```java
public class ConsumerRecord<K, V> {
    private final Stringtopic;
    private final int partition;
    private final long offset;
    private final long timestamp;
    //timestarnpType 有两种类型：CreateTime 和LogAppendTime, 分别代表消息创建的时间戳和消息追加到日志的时间戳。
    private final TimestampType timestampType;
    private final int serializedKeySize;
    private final int serializedValueSize;
    private final Headers headers;
    private final K key;
    private final V value;
    private volatile Long checksum;
／／省略若干方法
}
```

### 位移提交

​		对于 Kafka 中的分区而言，它的每条消息都有唯一 的 offset，用来表示消息在分区中对应 的位置 。 对于消费者而言 ， 它也有一个 offset 的概念，消费者使用 offset 来表示消费到分区中某个消息所在的位置。

​		在每次调用 poll()方法时，它返回的是还没有被消费过的消息集（当然这个前提是消息己经存储在 Kafka 中 了，并且暂不考虑异常情况的发生），要做到这一点，就需要记录上一 次消费时的消费位移 。 并且这个消费位移必须做持久化保存，而不是单单保存在内存中，否则消费者重启之后就无法知晓之前的消费位移 。在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的 。 而**在新消费者客户端中，消费位移存储在 Kafka 内 部的主题consumer offsets 中 。 这里把将消费位移存储起来（持久化）的动作称为“提交’，消费者在消费完消息之后需要执行消费位移的提交。**

​		**在Kafka 中默认的消费位移的提交方式是自动提交，这个由消费者客户端参数enable. auto. commit 配置，默认值为 true。当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数 auto. commit. interval. ms配置，默认值为 5 秒，此参数生效的前提是 enable. auto.commit 参数为 true** 。

​		在默认的方式下，消费者每隔 5 秒会将拉取到的每个分区中最大的消息位移进行提交 。自动位移提交的动作是在 poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。　　　　

### 位移提交过程导致重复消费的现象

​	如果在业务逻辑处理完之后，并且在同步位移提交前，程序出现了崩渍 ，那么待恢复之后又只能从上一次位移提交的地方拉取消息，由此在两次位移提交的窗口中出现了重复消费的现象。

​	KafkaConsumer 中的 seek（）方法提供了追前消费或 回溯消费。

```
public void seek(TopicPartition partition ,long offset)
```

 seek（）方法中的参数 partition 表示分区，而 offset 参数用来指定从分区的哪个位置开始消费。

​		?offset从那获取了

seek（）方法只能重置消费者分配到的分区的消费位置，而分区的分配是在poll（）方法的调用过程中实现的 。 也就是说，在执行 seek（）方法之前需要先执行一次 poll （）方法 ，等到分配到分区之后才可以重置消费位置 。 

```java
KafkaConsumer <String ,String> consumer= new KafkaConsumer<> (props);
consumer.subscribe(Arrays.asList(topic));
//timeout参数用来设置等待获取的超时时间。如果没有指 定timeout参数的值， 那么endOffsets() 方 法 的 等 待时 间由客户端参 数request.timeout.ms来设置，默认值为30000。
consumer . poll(Duration.ofMillis(lOOOO)）；
Set<TopicPartition> assignment = consumer.assignment（）；
for(TopicPartition tp : assignment) {
    consumer.seek(tp , 10) ;
    while(true) {
    ConsumerRecords<String , String> records = consumer.poll(Duration.ofMillis (1000)) ;
    //consume the record .
}
```

​		seek()方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息， 也可以通过这个方法来向后回溯若干消息， 这样为消息的消费提供了很大的灵活性。seek()方法也为我们提供了将消费位移保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。

### 再均衡

​		再均衡是指分区的所属权从一个消费者转移到另一消费者的行为， 它为消费组具备高可用性和伸缩性提供保障， 使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。 

​		附：不过在再均衡发生期间， 消费组内的消费者是无法读取消息的。 也就是说， 在再均衡发生期间的这一小段时间内， 消费组会变得不可用。 

​		附：另外， 当 一个分区被重新分配给另 一个消费者时， 消费者当前的状态也会丢失。 比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作， 之后这个分区又被分配给了消费组内的另 一个消费者，原来被消费完的那部分消息又被重新消费 一遍， 也就是发生了重复消费。 一般情况下， 应尽量避免不必要的再均衡的发生。

​		？subscribe()方法中有再均衡监听器ConsumerRebalanceListener, 在subscribe(Collection<String> topics, ConsumerRebalanceListener listener)和subscribe(Pattem pattern, ConsumerRebalanceListener listener)方法中都有它的身影。再均衡监听器用来设定发生再均衡动作前后的一些准备或收尾的动作。 ConsumerRebalanceListener是 一个接口.

### Kafka消费端重要的参数

| 参数名称                       | 默认值            | 参数释义                                                     |
| ------------------------------ | ----------------- | ------------------------------------------------------------ |
| bootstrap.servers              | “”                | 指定连接 Kafka 集群所需的 broker 地址清单                    |
| **key.deserializer**           |                   | 消息key对应的反序列化类，需要实现org.apache.kafka.common.serialization.Deserializer接口 |
| value.deserializer             |                   | 消息key 所对应的反序列化类，需要实现org.apache.kafka.common.serialization.Deserializer接口 |
| group.id                       | ""                | 消费者所隶属的消费组的唯一标识，即消费组的名称               |
| session. timeout.ms            | 10000             | 组管理协议中用来检测消费者是否失效的超时时间                 |
| max.poll.interval.ms           | 300000            | **消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时 间间 隔还没有发起 poll 操作，则消费组认为该消费者己离开了消费组 ，将进行再均衡操作** |
| auto.offset.reset              | latest            | 有效值为“ earliest ”＂ latest ” “ none”                      |
| enable.auto.commit             | true              | 是否开启自动提交消费位移的功能，默认开启                     |
| auto.commit.interval.ms        | 5000              | 当 enable.auto.commit 参数设置为 true 时才生效 ，表示开启自动提交消费位移功能 时自 动提交消费位移的时间间 隔 |
| partition.assignment. strategy |                   | 消费者的分区分配策略                                         |
| fetch .min.bytes               | 1( B ）           | Consumer 在一次拉取中从 Kafka 中拉取的最小数据量             |
| fetch .max.bytes               | 50MB              | Consumer 在一次拉取中从 Kafka 中拉取的最大数据量             |
| max.poll.records               | 500条             | Consumer 在一次拉取请求中拉取的最大消息数                    |
| connections.max.idle.ms        | 9分钟             | 用来指定在多久之后关闭限制的连接                             |
| isolation.level                | read_ uncommitted | 事务隔离级别。字符串类型，有效值为“ read_uncommitted ，和“ read committed ＂，表示消费者所消费到的位置,可以消费到 HW (High Watermark ）处的位置 |



## 主题管理：

> https://www.cnblogs.com/zjdxr-up/p/16124354.html

### 创建主题

创建主题：

​		1. 如果 broker 端配置参数 auto .create.topics .enable 设置为 true （默认值就是 true) ,那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为 num . partitions（默认值为1 ）、副本因子为 default.replication.factor （默认值为1 ）的主题。除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会按照配置参数 num.partitions 和 default.replication.factor 的值来创建一个相应的主题。

​		很多时候，这种自动创建主题的行为都是非预期的。除非有特殊应用需求，否则不建议将 auto.create.topics. enable 参数设置为 true，这个参数会增加主题的管理与维护的难度。

　　2. 通过命令创建主题

```bash
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-create --partitions 4 --replication-factor 2# 创建了一个分区数为 4 、 副本因子为 2 的主题;# 在执行完脚本之后，Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为／tmp/kafka-logs／
```

附：

- 生产者的分区分配是指为每条消息指定其所要发往的分区，消费者中的分区分配是指为消费者指定其可以消费消息的分区

```bash
#查看指定主题
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create-zk

#查看当前所有可用主题
bin/kafka-topics.sh --zookeeper localhost:2181/kafka -list

#删除主题
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --delete --topic topic-delete

#增加主题分区
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic-config --partitions 3
```

 

### 优先副本的选举

​		随着时间的更替， Kafka集群的broker节点不可避免地会遇到宕机或崩溃的问题， 当 分区的leader节点发生故障时， 其中 一个follower节点就会成为新的leader节点， 这样就会导致集群的负载不均衡， 从而影响整体的健壮性和稳定性。

​		为了能够有效地治理负载失衡的情况，Kafka引入了优先副本(preferred replica)的概念。所谓的优先副本 是指在 AR 集合列表中的第 一个副本 。 比如上面 主题 topic-partitions中 分区 0的AR集合列表(Replicas)为[1,2,0], 那么分区0 的优先副本即为1。 理想情况下，优先副本就是该分区的leader副本,所以也可以称之为 preferred leader。Kafka要确保所有主题的优先副本在Kafka集群中均匀分布?,这样就保证了所有分区的leader均衡 分布。 如果leader 分布过于集中， 就会造成集群 负载不均衡。 **所谓的优先副本的选举 是指通过一定的方式促使优先副本 选举为 leader副本， 以此来促进集群的负载均衡， 这 一行为也可以称为“ 分区平衡” 。**

​				？leader副本是什么，作用是什么，leader挂了 leader副本顶上吗 ？谁来操作？

​		在Kafka中可以提供分区自动平衡的功能， 与此对应的broker端参数是auto.leader.rebalance.enable,此参数的默认值为true, 即默认情况下此 功能是开启的。如果开启分区自动平衡的功能，则Kafka的控制器会启动一个定时任务， 这个定时任务会轮询所有的broker节点， 计算每个broker节点的分区不平衡率(broker中的不平衡率＝非优先副本的leader个数／分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认值为10%,如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。执行周期由参数leader.imbalance.check.interval.seconds控制，默认值为300秒，即5分钟。

​		附：不过在生产环境中不建议将auto.leader.rebalance.enable 设置为默认的true,因为这 可能引起负面的性能问题， 也有可能引起客户端 一 定时间的阻塞。 因为执行的时间无法自主掌控，如果在关键时期（比如电商大促波峰期）执行关键任务的关卡上执行优先副本的自动选举操作， 势必会有业务阻塞、 频繁超时之类的风险。 前面也分析过， 分区及副本的均衡也不能完全确保集群整体的均衡？，并且集群中一 定程度上的不均衡也是可以忍受的， 为防止出现关键时期“ 掉链子”的行为.

​		Kafka中kafka-perferred-replica-election.sh脚本提供了对分区leader副本进行重新平衡的功能。

```bash
bin/kafka-preferred-replica-election. sh --zookeeper localhost:2181/kafka
```

### 分区重分配

​		当要对集群中的一个节点进行有计划的下线操作时， 为了保证分区及副本的合理分配， 我们也希望通过某种方式能够将该节点上的分区副本迁移到其他的可用节点上。当集群中新增broker节点时， 只有新创建的主题分区才有可能被分配到这个节点上， 而之前的主题分区并不会自动分配到新加入的节点中， 因为在它们被创建时还没有这个新节点， 这样新节点的负载和原先节点的负载之间严重不均衡。 为了解决上述问题，**需要让分区副本再次进行合理的分配，也就是所谓的分区重分配**。**Kafka提供了kafka-reassign-partitions.sh脚本来执行分区重分配的工作， 它可以在集群扩容、broker节点失效的场景下对分区进行迁移。**

​				?分区副本重分配，分区不重新分配吗

​		kafka-reassign-partitions.sh脚本的使用分为3 个步骤：首先创建需要 一 个包含主题清单的JSON文件， 其次根据主题清单和broker节点清单生成 一 份重分配方案，最后根据这份方案执行具体的重分配动作。

​		分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子 ） ，新的副本将从分区的leader副本那里复制所有的数据。 根据分区的大小不同， 复制过程可能需要花一些时间， 因为数据是通过网络复制到新副本上的。在复制完成之后， 控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）。 注意在重分配的过程中要确保有足够的空间。

​		**分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。 数据复制会占用额外的资源， 如果重分配的量太大必然会严重影响整体的性能， 尤其是处于业务高峰期的时候。 减小重分配的粒度， 以小批次的方式来操作是一种可行的解决思路？。**

​		如果集群中某个主题或某个分区的流量在某段时间内特别大， 那么只靠减小粒度是不足以应对的， 这时就需要有一个限流的机制， 可以对副本间的复制流量加以限制来保证重分配期间整体服务不会受太大的影响 。副本间的复制限流有两种实现方式：kafka- config.sh脚本和kafka-reassign- partitions.sh脚本 。

### 如何选择合适的分区

​		在 Kafka 中 ，性能与分区数有着必然的关系，在设定分区数时一般也需要考虑性能的因素。对不同的硬件而言，其对应的性能也会不太一样。

​		在实际生产环境中，我们需要了解一套硬件所对应的性能指标之后才能分配其合适的应用和负荷，所以性能测试工具必不可少。Kafka 本身提供的用于生产者性能测试的kafka-producer­-perftest.sh 和用于消费者性能测试的 kafka-consumer-perf-test. sh 。

​		向一个只有1个分区和1个副本的主题 topic-1 中发送 100 万条消息，并且每条消息大小为 1024B ，生产者对应的 acks 参数为 l;

```bash
bin/kafka-producer-perf-test.sh --topic topic-1 --num-records 1000000 --record-size 1024 --throughput 一1 --producer-props bootstrap.servers=localhost:9092 acks=l
```

 		简单地消费主题topic-I中的100万条消息 

```bash
bin/kafka-consumer-perf-test. sh --topic topic-1 --messages 1000000 --broker-list localhost:9092
```

### 分区数越多吞吐量也越高？

​		针对分区数越多吞吐量越高这个命题进行反证， 其实要证明一个观点是错误的， 只需要举个反例即可， 本节的内容亦是如此 。不过本节并没有指明分区数越多吞吐量就越低这个观点， 并且具体吞吐量的数值和走势还会和磁盘、 文件系统、I/O 调度策略相关。分区数越多吞吐量 也就越高？网络上很多资料都认可这 一观点 ， 但实际上很多事情都会有一个临界值， 当超过这个临界值之后， 很多原本符合既定逻辑的走向又会变得不同。读者需要对此有清晰的认知，懂得去伪求真， 实地测试验证不失为一座通向真知的桥梁。

​		一味地增加分区数并不能使吞吐量 一直得到提升， 并且分区数也并不能一直增加， 如果超过默认的配置值， 还会引起 Kafka进程的崩溃。

​		当然分区数也不能一味地增加， 分区数会占用文件描述符(即一个文件下可建立的子文件数量默认为1024，超过默认值则会报 open too many files)， 而一个进程所能支配的文件描述符是有限的， 这也是通常所说的文件句柄的开销。 虽然我们可以通过修改配置来增加可用文件描述符的个数， 但凡事总有一个上限， 在选择合适的分区数之前， 最好再考量一下当前Kafka进程中已经使用的文件描述符的个数。



## [消息存储](https://www.cnblogs.com/zjdxr-up/p/16127749.html)

### 文件目录布局

​		如果分区规则?设置得合理， 那么所有的消息可以均匀地分布到不同的分区中， 这样就可以实现水平扩展。 不考虑多副本的情况， 一个分区对应一个日志(Log)。 为了防止Log过大，Kafka又引入了日志分段(LogSegment)的概念，将Log切分为多个LogSegment, 相当于一个巨型文件被平均分配为多个相对较小的文件， 这样也便于消息的维护和清理。 事实上， Log 和LogSegnient也不是纯粹物理意义上的概念， Log在物理上只以文件夹的形式存储， 而每个LogSegment对应于磁盘上的 一个日志文件 和两个索引文件， 以及可能的其他文件（比如以 " . txnindex"为后缀的事务索引文件）。

![](http://qiniu.58xuejia.cn/kafka_broke文件目录布局.png)

​		向Log中追加 消息时是顺序写入的， 只有最后 一 个LogSegment才能执行写入操作，在此之 前所有的LogSegment都 不能写入数据。

​		为了便于消息的检索， 每个LogSegment中的日志文件 （以 " . log"为文件后缀）都有对应的两个索引文件：偏移量 索引文件（以".index"为文件后缀）和时间戳索引文件（以". timeindex"为文件后缀）。 每个LogSegment 都有 一 个基准偏移量baseOffset, 用来表示当前LogSegment中第一 条消息的offset。 偏移量是一 个6 4位的长整型数， 日志文件和两个索引文件都是根据 基准偏移量(baseOffset)命名 的，名称固定为20 位数字， 没有达到的位数则用0填充。 比如第一 个LogSegment的基准偏移量为O, 对应的日志文件为00000000000000000000.log。

### 消息压缩

​		常见的压缩算法是数据量越大压缩效果越好， 一 条消息通常不会太大，这就导致压缩效果并不是太好。 而Kafka实现的压缩方式是将多条消息 一起进行压缩，这样可以保证较好的压缩效果。 在 一般情况下，生产者发送 的压缩数据在broker中也是保待压缩状态进行存储的，消费者从服 务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保待了端到端的压缩。

​				?消费端只需要一条，获取的也是压缩的吗

​		 Kafka日志中使用哪种压缩方式是通过参数compression.type来配置的， 默认值为"producer", 表示保留生产者使用的压缩方式。这个参数还可以配置为"gzip" "snappy" "lz4",分别对应GZ IP、 SNAPPY、 LZ 4这3种压缩算法。如果参数compression.type配置为"uncompressed" , 则表示不压缩。压缩率越小，压缩效果越好。

### 日志索引

​		每个日志分段文件对应了两个索引文件，主要用来提高查找消息的效率。偏移量索引文件用来建立消息偏移量（ offset ）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳（ timestamp ）来查找对应的偏移量小信息。

​		Kafka 中的索引文件以稀疏索引（ sparse index ）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引页 。 每当写入一定量（由broker 端参数log.index.interval.bytes 指定，默认值为 4096 ，即 4KB ）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小 log.index.interval.bytes的值，对应地可以增加或缩小索引项的密度。

### 日志文件及索引文件分段触发条件

​		日志分段文件达到一定的条件时需要进行切分，那么其对应的索引文件也需要进行切分。日志分段文件切分包含以下几个条件，满足其一 即可 。 (1) 当前日志分段文件的大小超过了broker 端参数 log.segment.bytes 配置的值。log.segment.bytes 参数的默认值为 1073741824 ，即 lGB 。 (2）当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于log.roll .ms或 log.roll.hours 参数配置的值。如果同时配置了 log.roll.ms 和 log.roll.hours 参数，那么 log.roll.ms 的优先级高 。 默认情况下，只配置了 log.ro ll.h ours 参数，其值为 168,即 7 天。 (3）偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 log. index.size .max.bytes 配置的值。 log.index. size .max. bytes 的默认值为 10485760 ，即 l0MB 。 (4）追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE,即要追加的消息的偏移量不能转变为相对偏移量（ offset - baseOffset > Integer.MAX_VALUE ）。

### 日志清理

​		Kafka 将 消息存储在磁盘中，为了 控制磁盘占用空间的不断增加就需要对消息做一 定的清理操作。 Kafka 中 每 一个分区副本都对应 一个 Log, 而Log又可以分为多个日志分段，这样也便于日志的清理操作。

​		 Kafka提供了两种日志清理策略。 (1)日志删除(LogRetention) : 按照一定的保留策略直接删除不符合条件的日志分段。 (2)日志压缩 (LogCompaction) : 针对每个消息的key进行整合， 对千有相同 key的不同value 值， 只保留 最后 一个版本。 

​		我们可以通过broker端参数log.cleanup.policy来设置 日志清理策略，此参数的默认值为"delete " , 即采用日志删除的清理策略。 如果要采用日志压缩的清理策略， 就需要将log.cleanup.policy且cy设置为"compact", 并且还需要将log.cleaner. enable (默认值为true )设定为true。 通过将log.cleanup.policy参数 设为"delete,compact" , 还可以同时支持日志删除和日志压缩两种策略。

​		？日志清理的粒度可以控制到主题级别， 比如log.cleanup.policy 对应的主题级别的参数为cleanup.policy

### 磁盘存储--页缓存/零拷贝技术

**页缓存**

​		页缓存是操作系统实现的一种主要的磁盘缓存， 以此用来减少对磁盘I/0 的操作。 具体来说， 就是把磁盘中的数据缓存到内存中， 把对磁盘的访间变为对内存的访问。 

​				附: 为了弥补性能上的差异， 现代操作系统越来越“ 激进地” 将内存作为磁盘缓存， 甚至会非常乐意将所有可用的内存用作磁盘缓存， 这样当内存回收时也几乎没有性能损失， 所有对于磁盘的读写也将经由统一的缓存。 

​		当一个进程准备读取磁盘上的文件内容时， 操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中， 如果存在（命中）则直接返回数据， 从而避免了对物理磁盘的I/0操作；如果没有命中， 则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存， 之后再将数据返回给进程。 同样，如果 一个进程需要将数据写入磁盘， 那么操作系统也会检测数据对应的页是否在页缓存中， 如果不存在， 则会先在页缓存中添加相应的页， 最后将数据写入对应的页。 被修改过后的页也就变成了脏页， 操作系统会在合适的时间把脏页中的 数据写入磁盘， 以保持数据的一致性。

 

**零拷贝**

​		除了消息顺序追加、页缓存等技术，Kafka 还使用 零拷 贝（ Zero-Copy ）技术来进一步提升性能 。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中?，而不需要经由应用程序之手 。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换? 。

​		对 Linux操作系统而言，零拷贝技术依赖于底层的sendfile() 方法实现 。对应于Java 语言FileChannal.transferTo()   方法的底层实现就是 sendfile()方法 。

​		零拷贝技术通过 DMA (Direct Memory Access) 技术将文件内容复制到内核模式下的 Read Buffer 中。零拷贝是针对内核模式而言的?， 数据在内核模式下实现了零拷贝。

? 

​	什么是零拷贝：https://blog.csdn.net/weixin_39406430/article/details/123715072



## [Controller选举机制，分区副本leader选举机制，再均衡机制 ](https://www.cnblogs.com/zjdxr-up/p/15026824.html)



### Kafka核心总控制器Controller

​		在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它**负责管理整个集群中所有分区和副本的状态**。

　　- 当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。

　　- 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。

　　- 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。

### Controller选举机制

​		在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller **临时节点**，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。
　　当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller。
　　

具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下：
- 监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化。
- 监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。
- 从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化。
- 更新集群的元数据信息，同步到其他普通的broker节点中。

### Partition副本选举Leader机制

　　controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从每个parititon的 replicas 副本列表中取出第一个broker作为leader，当然这个broker需要也同时在ISR列表里。这也成为**副本优先机制**；

### 消费者消费消息的offset记录机制

　　每个consumer会定期将自己消费分区的offset提交给 **kafka内部topic：__consumer_offsets**，提交过去的时候，**key是 consumerGroupId+topic+分区号，value就是当前offset的值**，kafka会定期清理topic里的消息，最后就保留最新的那条数据，因为__consumer_offsets可能会接收高并发的请求，kafka默认给其**分配50个分区**(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。

 　**一般情况下，当集群中第一次有消费者消费消息时会自动创建 __consumer_offsets，它的副本因子受 offsets.topic.replication.factor 参数的约束，默认值为3**

### 消费者Rebalance机制

　　消费者rebalance就是说如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他。如下情况可能会触发消费者rebalance
　　　　**1. consumer所在服务重启或宕机了**
　　　　**2. 动态给topic增加了分区**
　　　　**3. 消费组订阅了更多的topic**
　　

​		Rebalance过程如下
　　　　当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段。
　　　　**第一阶段：选择组协调器**
　　　　　　组协调器GroupCoordinator：每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance。						consumer group中的每个consumer启动时会向kafka集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接。
　　　　组协调器选择方式：
　　　　　　通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker就是这个consumer group的coordinator
　　　　　　公式：**hash(consumer group id) % __consumer_offsets主题的分区数 （50）**
　　　　**第二阶段：加入消费组JOIN GROUP**
　　　　　　在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段。在此阶段的消费者会向GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。然后GroupCoordinator 从一个consumer group中选择第一个加入group的consumer作为leader(消费组协调器)，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案。

​						？leader干啥用来着

　　　　**第三阶段（ SYNC GROUP)**
　　　　　　consumer leader通过给GroupCoordinator发送SyncGroupRequest？，接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader broker进行网络连接以及消息消费。



### 消费者Rebalance分区分配策略

　　主要有三种rebalance的策略：range、round-robin、sticky。
　　　　Kafka 提供了消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。默认情况为range分配策略。
　　假设一个主题有10个分区(0-9)，现在有三个consumer消费：
　　- range策略就是按照分区序号排序，假设 n＝分区数／消费者数量 = 3， m＝分区数%消费者数量 = 1，那么前 m 个消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区。比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer。
　　- round-robin策略就是轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer
　　- sticky策略就是在rebalance的时候，需要保证如下两个原则。
	　　	1）分区的分配要尽可能均匀 。
	2）分区的分配尽可能与上次分配的保持相同。
　　当两者发生冲突时，第一个目标优先于第二个目标 。这样可以最大程度维持原来的分区分配的策略。比如对于第一种range情况的分配，如果第三个consumer挂了，那么重新用sticky策略分配的结果如下：
		consumer1除了原有的0~3，会再分配一个7
		consumer2除了原有的4~6，会再分配8和9





面试：

​	kafka节点之间如何复制备份的？
​	kafka消息是否会丢失？为什么？
​	kafka最合理的配置是什么？
​	kafka的leader选举机制是什么？
​	kafka对硬件的配置有什么要求？
​	kafka的消息保证有几种方式？
​	kafka为什么会丢消息？
​	
​	

	避免消息堆积？
		1） 采用workqueue，多个消费者监听同一队列。
		2）接收到消息以后，而是通过线程池，异步消费。
	如何避免消息丢失？
		1） 消费者的ACK机制。可以防止消费者丢失消息。
		但是，如果在消费者消费之前，MQ就宕机了，消息就没了？
		2）可以将消息进行持久化。要将消息持久化，前提是：队列、Exchange都持久化